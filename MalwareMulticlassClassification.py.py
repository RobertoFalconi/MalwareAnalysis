# Student: Roberto Falconi 
# Student number: 1663546
# Sapienza - University of Rome
# Master's Degree in Engineering in Computer Science
# Machine Learning course - Homework 1: Malware Analysis
# -*- coding: utf-8 -*-

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import os 
import difflib
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

classificatore = RandomForestClassifier

print('\nStarting program\n')                       # Starting program

print('Dataset loading')                       # Dataset loading

df = pd.read_csv('sha256_family.csv', encoding="utf-8")

print("Elements permutation")                       # Elements permutation

df = df.reindex(np.random.permutation(df.index)).reset_index(drop=True)

print("Feature families discretization using One-Hot Encoding") # Feature families discretization using One-Hot Encoding (Y)

y_true_aux = []                         # y_true_aux temporarily contains all the families' element
for elem in df.family:
    y_true_aux.append(elem)

y_true = []                             #y_true contains all the families' elements with more then 20 elements
for elem in y_true_aux:
    if y_true_aux.count(elem) > 20:
        y_true.append(elem)

family_list = []                        #family_list contains the names of every family
for elem in y_true:
    if elem not in family_list:
        family_list.append(elem)

i=0
indici_da_togliere = []

for elem in df.family:                  # deleting from the dataset all families with less then 20 elements
    if elem not in family_list:
        indici_da_togliere.append(i)
    i+=1
df.drop(indici_da_togliere,inplace = True)
df = df.reset_index(drop=True)

for elem in family_list:                # adding to the dataset columns (one per family) with all zeros
    df[elem] = 0

for elem in df.index.get_values():      # setting 1 to the own column (family) of each element
    df.set_value(elem, df.get_value(elem, "family"), 1)

# Creazione liste di features

features = []

# Riempimento liste di features

for file_feature_vectors in df.sha256:
    file_object = open("feature_vectors/"+file_feature_vectors, "r")
    for riga in file_object:
        if riga.split("::").__len__() == 2:
            #valore = riga.split("::")[1].strip()
            if riga not in features:
                features.append(riga)
                df[riga] = 0
    file_object.close()

print("out of cycle 1")
# Inserimento delle liste di feature nel dataset inizializzate a 0

i = 0
for file_feature_vectors in df.sha256:
    file_object = open("feature_vectors/"+file_feature_vectors, "r")
    features.clear()
    for riga in file_object:
        if riga.split("::").__len__() == 2:
            #valore = riga.split("::")[1].strip()
            if riga not in features:
                features.append(riga)
    for elem in features:
        df.set_value(i, elem, 1)
    file_object.close()
    i = i + 1

print("out of cycle 2")

print("Elements conversion in float values")    # Elements conversion in float values

del df['family']

del df['sha256']

df = df.astype('float64')

print("Dataset ready")                             # Dataset is now ready to analysis

nome_classificatore = str(classificatore).split(".")[-1].split("'")[0]
print("Running " + nome_classificatore + " analysis\n")         # Running Random Forest analysis

print("Binary Classifiers Malware Family\n")

denominatore = np.zeros(len(df),dtype=float)
colonna = []
MegaColonna = []
iteration = 0

for elem in family_list:
    print("Family #", iteration)
    iteration += 1
    df2 = df
    y = df2[elem].values
    for elemm in family_list:
        df2 = df2.drop(elemm, axis=1)
    X = df2.values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) # to avoid overfitting
    
    if (classificatore is SVC):
        classifier = SVC(kernel='linear', probability=True)
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_test)
    elif (classificatore is RandomForestClassifier):
        classifier = RandomForestClassifier()
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_test)
    elif (classificatore is LogisticRegression):
        classifier = LogisticRegression()
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_test)

    accuracy = cross_val_score(classifier, X_train, y_train, scoring='accuracy')
    balanced = cross_val_score(classifier, X_train, y_train, scoring='balanced_accuracy')
    recall = cross_val_score(classifier, X_train, y_train, scoring='recall_weighted')
    precision = cross_val_score(classifier, X_train, y_train, scoring='precision_weighted')
    f1 = cross_val_score(classifier, X_train, y_train, scoring='f1_weighted')
    misclassification = len(y_pred) - accuracy_score(y_test, y_pred, normalize=False)

    print(nome_classificatore + " " + elem + " classification report: ", classification_report(y_test, y_pred))
    print(nome_classificatore + " " + elem + " accuracy: ", accuracy)
    print(nome_classificatore + " " + elem + " balanced accuracy: ", balanced)
    print(nome_classificatore + " " + elem + " misclassification: ", misclassification)
    print(nome_classificatore + " " + elem + " recall: ", recall)
    print(nome_classificatore + " " + elem + " precision: ", precision)
    print(nome_classificatore + " " + elem + " f1: ", f1)

    proba = cross_val_predict(classifier, X, y, method='predict_proba')

    colonna.clear()
    i = 0
    for r in proba:
        a = 1 - r[0].__int__()
        colonna.append(a)
        denominatore[i] += a
        i += 1

    MegaColonna.append([float(i) for i in colonna[:]])

print("Multiclass Classifier Malware Family\n")

i = j = 0

for i in range(family_list.__len__()):
    for j in range(len(df)):
        MegaColonna[i][j] = MegaColonna[i][j]/denominatore[j]

i = j = 0
threshold = 0.50
y_predicted = []

for i in range(len(df)):  # i indica l'elemento
    mis = 0
    for j in range(family_list.__len__()):            # j indica la famiglia
        if MegaColonna[j][i] > threshold:
            y_predicted.append(family_list[j])
            mis = 1
    if mis == 0:
        y_predicted.append("Misclassification")

# CONFUSION MATRIX

print(nome_classificatore + " Confusion Matrix: ", (confusion_matrix(y_true, y_predicted)))

# ACCURACY SCORE

print(nome_classificatore + " Accuracy: %0.2f%%" % (accuracy_score(y_true, y_predicted)*100))

# PRECISION SCORE

print(nome_classificatore + " Precision: %0.2f%%" % (precision_score(y_true, y_predicted, average='weighted')*100))

# RECALL SCORE

print(nome_classificatore + " Recall: %0.2f%%" % (recall_score(y_true, y_predicted, average='weighted')*100))

# F1 SCORE

print(nome_classificatore + " F1: %0.2f%%" % (f1_score(y_true, y_predicted, average='weighted')*100))

